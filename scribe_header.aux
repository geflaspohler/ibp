\relax 
\citation{Blei2010}
\citation{Newman}
\citation{Newman}
\@writefile{toc}{\contentsline {section}{\numberline {1}Background}{1}}
\newlabel{sec:back}{{1}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The graphical model representing the generative process for LDA (left) and HDP (right) [\citet  {Newman}]. The shaded nodes represent the observed data, and the rest of the structure in the problem is provided by the graphical model.}}{1}}
\newlabel{fig:graph}{{1}{1}}
\citation{Raykov2016}
\citation{Raykov2016}
\citation{Gershman2011}
\citation{Gershman2011}
\citation{Griffiths2011}
\@writefile{toc}{\contentsline {section}{\numberline {2}Motivation}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Given simulated 2-$D$ data (a), a comparison between the clusters recovered by a parametric $K$-means clustering algorithm (b) and nonparametric DP clustering (c) [\citet  {Raykov2016}]}}{2}}
\newlabel{fig:cluster}{{2}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces A comparison between the structure implied by the CRP model (left) vs the IBP model (right). In the CRP, a data point (customer) is identified with a single cluster (table) and the data point's properties are entirely determined by that cluster. In the IBP, each data point (customer) can be associated with a potentially infinite number of dishes (features), which influence the data point's expression. The above matrices represent this structure visually [\citet  {Gershman2011}].}}{3}}
\newlabel{fig:ibp_crp}{{3}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Indian Buffet Process Model}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Latent Class Models}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Latent Feature Models}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The decomposition of the feature vector $\mathbf  {F}$ into a binary, indicator matrix $\mathbf  {Z}$ (left) and a value matrix $\mathbf  {V}$ (right). The value matrix can be either real or integer valued.}}{4}}
\newlabel{fig:decomp}{{4}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Defining a prior over infinite binary matrices}{4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Defining via stochastic process (IBP)}{4}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces An example of the matrix $\mathbf  {Z}$ produced by running the IBP with $\alpha = 10$. The first customer tried 17 dishes. The second customer sampled 7 of those dishes and three new dishes. The process was repeated for a total of 20 customers.}}{5}}
\newlabel{fig:ex}{{5}{5}}
\newlabel{eq:ibp}{{1}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.2}Defining as limit of finite model}{5}}
\newlabel{eq:pz}{{4}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The transformation of an arbitrary matrix to its \textit  {left-ordered form} via the many-to-one \textit  {lof()} function.}}{6}}
\newlabel{fig:lof}{{6}{6}}
\newlabel{eq:pe}{{5}{6}}
\citation{Griffiths2011}
\newlabel{eq:limit}{{6}{7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.3}Properties of IBP}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Inference in the IBP Model}{7}}
\newlabel{sec:gibbs}{{3.4}{7}}
\newlabel{eq:dish}{{7}{7}}
\citation{Griffiths2011}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Examples: Linear-Gaussian Latent Feature Model}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Data and results for the application of infinite linear-Gaussian model to images. (a) Four sample images from the data set. (b) The posterior mean of the weights for the four most frequent binary features after 1000 samples. These features correspond almost perfectly to the presence/absence of the four objects. (c) Reconstructions of the images in (a) using the binary features inferred for the images. The lower panels show the values of the parameters/hyperparameters throughout iterations of Gibbs sampling.}}{8}}
\newlabel{fig:exp}{{7}{8}}
\citation{Griffiths2011}
\bibstyle{apalike}
\bibdata{scribeadd}
\bibcite{Blei2010}{{1}{2010}{{Blei et~al.}}{{}}}
\bibcite{Gershman2011}{{2}{2011}{{Gershman and Blei}}{{}}}
\bibcite{Griffiths2011}{{3}{2011}{{Griffiths et~al.}}{{}}}
\bibcite{Newman}{{4}{2009}{{Newman et~al.}}{{}}}
\bibcite{Raykov2016}{{5}{2016}{{Raykov et~al.}}{{}}}
